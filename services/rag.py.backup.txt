# services/rag.py
from __future__ import annotations
import os, glob, csv, re, calendar
from datetime import date, timedelta
from typing import Optional, List, Tuple, Dict

from chromadb import PersistentClient
from chromadb.config import Settings
from chromadb.utils import embedding_functions

import streamlit as st
from dotenv import load_dotenv
load_dotenv()

import sys, httpx
print("ğŸ§  Python ì‹¤í–‰ ê²½ë¡œ:", sys.executable)
print("ğŸ“¦ httpx ë²„ì „:", httpx.__version__)

# ---------------- OpenAI í´ë¼ì´ì–¸íŠ¸ ----------------
try:
    from openai import OpenAI as _OpenAI
    import httpx
except Exception:
    _OpenAI = None
    httpx = None

def _make_openai_client() -> Optional["_OpenAI"]:
    if not _OpenAI:
        return None
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ .envì—ì„œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    # openai 1.0+ ë²„ì „ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ë§Œìœ¼ë¡œ ì´ˆê¸°í™” ê°€ëŠ¥
    os.environ["OPENAI_API_KEY"] = api_key
    
    http_proxy  = os.getenv("HTTP_PROXY")  or os.getenv("http_proxy")
    https_proxy = os.getenv("HTTPS_PROXY") or os.getenv("https_proxy")
    print(f"------------${http_proxy}")
    print(f"------------${https_proxy}")

    # í”„ë¡ì‹œ ìˆìœ¼ë©´ httpx.Clientë¥¼ ë§Œë“¤ì–´ì„œ ì „ë‹¬
    client_args = {"timeout": 30.0}
    if http_proxy or https_proxy:
        proxies = {}
        if http_proxy:
            proxies["http://"] = http_proxy
        if https_proxy:
            proxies["https://"] = https_proxy
        client_args["proxies"] = proxies

    # OpenAI 1.44+ ì—ì„œëŠ” http_client=Client(**args) í˜•íƒœ
    http_client = httpx.Client(**client_args) if client_args else None
    return _OpenAI(http_client=http_client)

_OPENAI_CLIENT = _make_openai_client()
_OPENAI_EMB_MODEL = os.getenv("EMB_MODEL", "text-embedding-3-small")

# ---------------- ì„ë² ë”© í•¨ìˆ˜ (ì¶©ëŒ í•´ê²° ë²„ì „) ----------------
class OpenAIEmbedder:
    """chromadbìš© ì„ë² ë”: .name ì†ì„±ê³¼ __call__ ì œê³µ"""
    def __init__(self, client, model_name: str):
        self.client = client
        self.model_name = model_name
        self._name = f"openai:{model_name}"
        
    @property
    def name(self):
        return self._name

    def __call__(self, input: list[str]) -> list[list[float]]:
        """Chroma 0.4.16+ëŠ” input í‚¤ì›Œë“œ ì¸ìë¥¼ ë°›ìŒ"""
        resp = self.client.embeddings.create(model=self.model_name, input=input)
        return [d.embedding for d in resp.data]

def _embedding_function():
    if _OPENAI_CLIENT:
        embedder = OpenAIEmbedder(_OPENAI_CLIENT, os.getenv("EMB_MODEL", "text-embedding-3-small"))
        
        # ChromaDBê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœ: í•¨ìˆ˜ + name() í˜¸ì¶œ ê°€ëŠ¥
        def func(texts: list[str]) -> list[list[float]]:
            return embedder(texts)
        
        # name()ì„ ë©”ì„œë“œì²˜ëŸ¼ ë¶™ì—¬ì£¼ê¸°
        func.name = lambda: embedder.name
        return func
    else:
        return embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )

# ---------------- ê²½ë¡œ ì„¤ì • ----------------
DBDIR  = "data/vectorstore/chroma"
FAQDIR = "data/vectorstore"

def _chroma_client():
    os.makedirs(DBDIR, exist_ok=True)
    return PersistentClient(path=DBDIR)

# ---------------- íŒŒì¼ ë¦¬ë” ----------------
def _read(path: str) -> str:
    if path.lower().endswith((".md", ".txt")):
        return open(path, "r", encoding="utf-8").read()
    try:
        from pypdf import PdfReader
        return "\n".join(page.extract_text() or "" for page in PdfReader(path).pages)
    except Exception:
        return ""

def _read_qa_csv(path: str) -> list[tuple[str, str]]:
    rows = []
    with open(path, encoding="utf-8") as f:
        for r in csv.DictReader(f):
            q = (r.get("question") or "").strip()
            a = (r.get("answer") or "").strip()
            if q and a:
                rows.append((q, a))
    return rows

def _read_qa_md(path: str) -> list[tuple[str, str]]:
    # ë§¤ìš° ë‹¨ìˆœ: "### Q:" / "A:" í¬ë§·
    txt = open(path, "r", encoding="utf-8").read()
    pairs = []
    for block in txt.split("### Q:")[1:]:
        q, _, rest = block.partition("\n")
        a_tag = "A:"
        a = rest.split("\n", 1)[0] if a_tag not in rest else rest.split(a_tag, 1)[1].strip()
        q, a = q.strip(), a.strip()
        if q and a:
            pairs.append((q, a))
    return pairs

# ---------------- ì¸ë±ìŠ¤ ë¹Œë“œ ----------------
def build_index() -> None:
    os.makedirs(DBDIR, exist_ok=True)
    cli = _chroma_client()
    col = cli.get_or_create_collection("faqs", embedding_function=_embedding_function())

    # 1) PDF/MD/TXT ë¬¸ì„œ ìƒ‰ì¸
    files = glob.glob(f"{FAQDIR}/*.md") + glob.glob(f"{FAQDIR}/*.txt") + glob.glob(f"{FAQDIR}/*.pdf")
    ids, docs, metas = [], [], []
    for f in files:
        txt = _read(f)
        if not txt.strip():
            continue
        ids.append(os.path.basename(f))
        docs.append(txt[:10000])
        metas.append({"path": f})
    if ids:
        col.upsert(ids=ids, documents=docs, metadatas=metas)

    # 2) CSV/MD Q&A ìƒ‰ì¸
    qa_files = glob.glob(f"{FAQDIR}/*.csv") + glob.glob(f"{FAQDIR}/faq_qa.md") + glob.glob(f"{FAQDIR}/*_qa.md")
    q_ids, q_docs, q_metas = [], [], []
    for f in qa_files:
        pairs = _read_qa_csv(f) if f.endswith(".csv") else _read_qa_md(f)
        for idx, (q, a) in enumerate(pairs):
            q_ids.append(f"{os.path.basename(f)}::Q{idx+1}")
            q_docs.append(f"[Q] {q}\n[A] {a}")
            q_metas.append({"path": f, "type": "qa"})
    if q_ids:
        col.upsert(ids=q_ids, documents=q_docs, metadatas=q_metas)

    cli.persist()

# ---------------- ë§ˆê°ì¼ ê·œì¹™ & ì˜ì—…ì¼ ë³´ì • ----------------
ADJUST_TO_BUSINESS_DAY = os.getenv("RAG_DEADLINE_BUSINESS_DAY", "1") in ("1", "true", "True")
HOLIDAYS_FILE = os.getenv("RAG_HOLIDAYS_FILE", "data/vectorstore/holidays_kr.csv")

_HOLIDAYS: set[date] = set()
def _load_holidays() -> set[date]:
    days: set[date] = set()
    try:
        if os.path.exists(HOLIDAYS_FILE):
            with open(HOLIDAYS_FILE, encoding="utf-8") as f:
                for line in f:
                    s = line.strip().split(",")[0]
                    if not s:
                        continue
                    try:
                        y, m, d = s.split("-")
                        days.add(date(int(y), int(m), int(d)))
                    except:
                        pass
    except:
        pass
    return days
_HOLIDAYS = _load_holidays()

def _adjust_to_business_day(d: date, prefer: str = "previous") -> date:
    step = -1 if prefer == "previous" else +1
    cur = d
    while cur.weekday() >= 5 or cur in _HOLIDAYS:  # 5=í† , 6=ì¼
        cur = cur + timedelta(days=step)
    return cur

_DEADLINE_ANY = re.compile(r"(ë§ˆê°ì¼|ë§ˆê°|ë§ì¼)", re.I)
_THIS_MONTH   = re.compile(r"(ì´ë²ˆ\s*ë‹¬|ì´ë²ˆë‹¬)", re.I)
_NEXT_MONTH   = re.compile(r"(ë‹¤ìŒ\s*ë‹¬|ìµì›”)", re.I)
_PREV_MONTH   = re.compile(r"(ì§€ë‚œ\s*ë‹¬|ì „ì›”)", re.I)
_YEAR_MONTH   = re.compile(r"(?:(?P<y>\d{4})\s*[./-]?\s*(ë…„)?\s*)?(?P<m>1[0-2]|0?[1-9])\s*(ì›”)?")

def _shift_month(dt: date, delta: int) -> date:
    y, m = dt.year, dt.month + delta
    while m < 1:
        y -= 1; m += 12
    while m > 12:
        y += 1; m -= 12
    return date(y, m, 1)

def _end_of_month(dt: date) -> date:
    last = calendar.monthrange(dt.year, dt.month)[1]
    return date(dt.year, dt.month, last)

def _parse_target_month_from_text(q: str, today: date) -> Optional[date]:
    t = q.strip()
    if _THIS_MONTH.search(t): return date(today.year, today.month, 1)
    if _NEXT_MONTH.search(t): return _shift_month(today, +1)
    if _PREV_MONTH.search(t): return _shift_month(today, -1)
    m = _YEAR_MONTH.search(t)
    if m:
        yy = m.group("y")
        mm = int(m.group("m"))
        yyyy = int(yy) if yy else today.year
        return date(yyyy, mm, 1)
    return None

# ---------------- ì§ˆì˜ ì‘ë‹µ ----------------
def rag_answer(question: str, k: int = 3) -> tuple[str, list[dict]]:
    # 0) ë§ˆê°ì¼ ê³„ì—´ íŠ¹ìˆ˜ì²˜ë¦¬ (RAG ì „ì— ê²°ì •ë¡ )
    if _DEADLINE_ANY.search(question):
        today = date.today()
        target = _parse_target_month_from_text(question, today) or date(today.year, today.month, 1)
        eom = _end_of_month(target)
        eom_adj = _adjust_to_business_day(eom, prefer=os.getenv("RAG_DEADLINE_PREFER", "previous")) \
                  if ADJUST_TO_BUSINESS_DAY else eom
        y, m = target.year, target.month
        msg = (
            "ì§€ì¶œê²°ì˜ì„œ ë§ˆê°ì¼ì€ ì¼ë°˜ì ìœ¼ë¡œ ë§¤ì›” ë§ì¼ì…ë‹ˆë‹¤.\n"
            f"ìš”ì²­í•˜ì‹  ê¸°ê°„: **{y}ë…„ {m}ì›”**\n"
            f"ê¸°ë³¸ ë§ì¼: {eom.strftime('%Y-%m-%d')}\n"
            f"ì˜ì—…ì¼ ë³´ì •: **{eom_adj.strftime('%Yë…„ %mì›” %dì¼')}**"
        )
        return msg, []

    # 1) ë¬¸ì„œ/QA RAG
    #cli = PersistentClient(Settings(persist_directory=DBDIR, is_persistent=True))
    cli = PersistentClient(path=DBDIR)
    col = cli.get_or_create_collection("faqs", embedding_function=_embedding_function())
    r = col.query(query_texts=[question], n_results=k)
    ctx = "\n\n".join(r["documents"][0]) if r and r.get("documents") else ""

    # 2) LLM ìƒì„± (ìˆìœ¼ë©´)
    if _OPENAI_CLIENT is not None:
        msgs = [
            {"role": "system", "content": "ì‚¬ë‚´ ê·œì •/FAQë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ê²°íˆ í•œêµ­ì–´ë¡œ ë‹µí•˜ì„¸ìš”. ì¸ìš©ì€ ë”°ì˜´í‘œë¡œ í‘œì‹œ."},
            {"role": "user",   "content": f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n\n[ì§ˆë¬¸]\n{question}"},
        ]
        try:
            a = _OPENAI_CLIENT.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=msgs, temperature=0.1,
            )
            return a.choices[0].message.content, (r["metadatas"][0] if r else [])
        except Exception:
            pass

    # 3) í‚¤ê°€ ì—†ê±°ë‚˜ LLM ì‹¤íŒ¨ ì‹œ ìŠ¤ë‹ˆí« ë°˜í™˜
    return (f"ìƒìœ„ ìŠ¤ë‹ˆí«:\n{ctx[:1200]}\n\n(OPENAI_API_KEY ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ ìŠ¤ë‹ˆí«ë§Œ í‘œì‹œ)",
            r["metadatas"][0] if r else [])

# ---------------- ê¸°ë³¸ UI ----------------

# ì œëª©
st.title("í…ìŠ¤íŠ¸ ì…ë ¥ ì‹œ rag_answer() ìˆ˜í–‰")


# í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ
user_input = st.text_input("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")


# ----------------- ì‚¬ìš©ì ì…ë ¥ì— ë”°ë¼ PDF/MD/TXTë¥¼ vectorstoreë¡œ ìƒ‰ì¸ -----------------
if user_input:
    st.write(f"ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸: {user_input}")
    
    # OpenAI í‚¤ ì²´í¬
    if _OPENAI_CLIENT is None:
        st.write("âŒ OPENAI_API_KEY ì—†ìŒ")
    else:
        try:
            r = _OPENAI_CLIENT.models.list()
            print("âœ… í‚¤ ì •ìƒì…ë‹ˆë‹¤. ëª¨ë¸ ìˆ˜:", len(r.data))
        except Exception as e:
            print("âŒ í‚¤ ì˜¤ë¥˜:", e)
    
    # ìƒ‰ì¸ ë° ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸
    try:
        build_index()  # ê¸°ì¡´ build_index() í˜¸ì¶œ
        cli = PersistentClient(path=DBDIR)
        col = cli.get_or_create_collection("faqs_openai")  # ìƒˆ ì»¬ë ‰ì…˜ ì´ë¦„ ì‚¬ìš©
        st.write("true" if col.count() > 0 else "false")
    except Exception as e:
        st.write("false")
        print("âŒ ë¹Œë“œ ì˜¤ë¥˜:", e)