import streamlit as st
import os, glob, re
import pandas as pd
from datetime import datetime, timedelta
from chromadb import PersistentClient
from services.rag import _embedding_function, _read_qa_csv, _read_qa_md, FAQDIR, DBDIR, _OPENAI_CLIENT

# ---------------- ê¸°ë³¸ ì„¤ì • ----------------
st.set_page_config(page_title="RAG FAQ ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸ“š RAG ê¸°ë°˜ FAQ ì§ˆì˜ ì‹œìŠ¤í…œ")

# ---------------- ìˆ¨ê¹€/ì •ì • íŒŒì¼ ë¡œë” ----------------
def _read_hidden_data():
    """hidden/ ë° correction/ í´ë” ë‚´ìš© í†µí•©"""
    hidden_dir = os.path.join(FAQDIR, "hidden")
    correction_dir = os.path.join(FAQDIR, "correction")
    hidden_txt, correction_txt = [], []

    for folder, acc in [(hidden_dir, hidden_txt), (correction_dir, correction_txt)]:
        if not os.path.exists(folder):
            continue
        for f in glob.glob(os.path.join(folder, "*.txt")) + glob.glob(os.path.join(folder, "*.csv")):
            try:
                acc.append(open(f, encoding="utf-8").read())
            except Exception as e:
                st.warning(f"âš  {folder} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    hidden_rules = "\n".join(hidden_txt)
    correction_rules = "\n".join(correction_txt)
    return hidden_rules, correction_rules


# ---------------- ì¡°ì§ë„ ë¶„ì„ ----------------
def _count_members_from_org(org_path: str, leader_name: str) -> tuple[int | None, str | None]:
    """CSV ì¡°ì§ë„ì—ì„œ íŒ€ì¥ ì´ë¦„ìœ¼ë¡œ íŒ€ì› ìˆ˜ì™€ íŒ€ëª… ë°˜í™˜"""
    try:
        df = pd.read_csv(org_path)
        if "íŒ€ì¥" not in df.columns:
            return None, None

        row = df[df["íŒ€ì¥"] == leader_name]
        if row.empty:
            return None, None

        if "íŒ€ì›ìˆ˜" in df.columns:
            team_count = int(row.iloc[0]["íŒ€ì›ìˆ˜"])
        else:
            members_str = str(row.iloc[0].get("íŒ€ì›", "")).strip()
            team_count = len([m for m in members_str.split(",") if m.strip()])

        team_name = row.iloc[0].get("íŒ€ëª…", None)
        return team_count, team_name

    except Exception as e:
        print(f"âŒ ì¡°ì§ë„ CSV íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None, None


# ---------------- ìƒ‰ì¸ ë¹Œë“œ ----------------
def safe_build_index():
    """ëª¨ë“  ë¬¸ì„œ í˜•ì‹(pdf, txt, csv, xlsx, md)ì„ ìƒ‰ì¸"""
    os.makedirs(DBDIR, exist_ok=True)
    cli = PersistentClient(path=DBDIR)

    try:
        cli.delete_collection("faqs_openai")
        st.success("âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
    except Exception:
        st.info("â„¹ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—†ìŒ, ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    col = cli.get_or_create_collection("faqs_openai", embedding_function=_embedding_function())

    ids, docs, metas = [], [], []
    exts = [".md", ".txt", ".pdf", ".csv", ".xlsx"]
    files = []
    for ext in exts:
        files.extend(glob.glob(os.path.join(FAQDIR, f"*{ext}")))

    MAX_CHARS = 6000

    for f in files:
        ext = os.path.splitext(f)[1].lower()
        text = ""

        try:
            if ext in [".md", ".txt"]:
                with open(f, "r", encoding="utf-8") as fp:
                    text = fp.read()

            elif ext == ".pdf":
                from pypdf import PdfReader
                reader = PdfReader(f)
                text = "\n".join([p.extract_text() or "" for p in reader.pages])

            elif ext == ".csv":
                df = pd.read_csv(f, encoding="utf-8")
                text = "\n".join([
                    ", ".join([f"{col}: {str(val)}" for col, val in row.items()])
                    for _, row in df.iterrows()
                ])

            elif ext == ".xlsx":
                from openpyxl import load_workbook
                wb = load_workbook(f, data_only=True)
                for sheet in wb.sheetnames:
                    ws = wb[sheet]
                    for row in ws.iter_rows(values_only=True):
                        line = ", ".join([str(v) for v in row if v is not None])
                        text += line + "\n"

        except Exception as e:
            st.warning(f"âš ï¸ {os.path.basename(f)} ì½ê¸° ì˜¤ë¥˜: {e}")
            continue

        if text.strip():
            for i in range(0, len(text), MAX_CHARS):
                chunk = text[i:i + MAX_CHARS]
                ids.append(f"{os.path.basename(f)}_part{i//MAX_CHARS+1}")
                docs.append(chunk)
                metas.append({"path": f, "ext": ext, "part": i//MAX_CHARS+1})

    if ids:
        try:
            col.upsert(ids=ids, documents=docs, metadatas=metas)
            st.success(f"âœ… {len(ids)}ê°œ ë¬¸ì„œ ìƒ‰ì¸ ì™„ë£Œ")
        except Exception as e:
            st.error(f"âŒ ì—…ì„œíŠ¸ ì‹¤íŒ¨: {e}")

    qa_files = glob.glob(f"{FAQDIR}/*.csv") + glob.glob(f"{FAQDIR}/faq_qa.md") + glob.glob(f"{FAQDIR}/*_qa.md")
    q_ids, q_docs, q_metas = [], [], []
    for f in qa_files:
        pairs = _read_qa_csv(f) if f.endswith(".csv") else _read_qa_md(f)
        for idx, (q, a) in enumerate(pairs):
            q_ids.append(f"{os.path.basename(f)}::Q{idx+1}")
            q_docs.append(f"[Q] {q}\n[A] {a}")
            q_metas.append({"path": f, "type": "qa"})
    if q_ids:
        col.upsert(ids=q_ids, documents=q_docs, metadatas=q_metas)
        st.success(f"âœ… {len(q_ids)}ê°œ Q&A ìƒ‰ì¸ ì™„ë£Œ")


# ---------------- RAG ì§ˆì˜ ----------------
def safe_rag_query(question: str, k: int = 3, show_sources: bool = False):
    cli = PersistentClient(path=DBDIR)
    col = cli.get_or_create_collection("faqs_openai", embedding_function=_embedding_function())
    r = col.query(query_texts=[question], n_results=k)

    ctx = "\n\n".join(r["documents"][0]) if r and r.get("documents") else ""
    metas = r["metadatas"][0] if r and r.get("metadatas") else []

    now = datetime.now()
    today_str = now.strftime("%Y-%m-%d (%A)")
    week_start = (now - timedelta(days=now.weekday())).strftime("%Y-%m-%d")
    week_end = (now + timedelta(days=6 - now.weekday())).strftime("%Y-%m-%d")
    month_str = now.strftime("%Y-%m")

    hidden_context, correction_rules = _read_hidden_data()

    designated_amounts = {}
    for line in hidden_context.splitlines():
        m = re.match(r"(\S+)\s*(\d+(?:,\d+)*)ì›", line)
        if m:
            rank, amt = m.groups()
            designated_amounts[rank] = int(amt.replace(",", ""))

    match_name_rank = re.search(r"([ê°€-í£A-Za-z]+)\s*(íŒ€ì¥|ë¶€ì¥|ì„ì›|ì°¨ì¥|ê³¼ì¥|ëŒ€ë¦¬|ì‚¬ì›)", question)
    user_name, user_rank = (match_name_rank.groups() if match_name_rank else (None, None))

    org_path = os.path.join(FAQDIR, "org_info.csv")
    member_count, team_name = _count_members_from_org(org_path, user_name) if user_name else (None, None)

    team_info_text, auto_calc_text = "", ""
    if member_count and team_name:
        team_info_text = f"{team_name} ({user_rank} {user_name})ì˜ íŒ€ì› ìˆ˜ëŠ” {member_count}ëª…ì…ë‹ˆë‹¤."
    if "ì—…ë¬´ì¶”ì§„ë¹„" in question and user_rank in designated_amounts:
        base = designated_amounts[user_rank]
        if member_count:
            total = base * member_count
            auto_calc_text = f"ğŸ’° ìë™ ê³„ì‚°: {user_rank} {user_name} - íŒ€ì› {member_count}ëª… Ã— {base:,}ì› = {total:,}ì›"
        else:
            auto_calc_text = f"ğŸ’° ìë™ ê³„ì‚°: {user_rank} ê¸°ì¤€ 1ì¸ë‹¹ {base:,}ì›"

    system_prompt = (
        f"ì˜¤ëŠ˜ì€ {today_str}ì´ë©°, ì´ë²ˆ ì£¼ëŠ” {week_start}~{week_end}, ì´ë²ˆ ë‹¬ì€ {month_str}ì›”ì…ë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
        "hidden í´ë”ì˜ ë‚´ìš©ì€ ë‚´ë¶€ ê·œì¹™ ì°¸ê³ ìš©ì´ë©°, ë‹µë³€ì— ì§ì ‘ ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.\n\n"
        f"[ìˆ¨ê¹€ ê·œì¹™]\n{hidden_context}\n"
        f"[ì •ì • ìë£Œ]\n{correction_rules}\n"
        f"[ì¡°ì§ë„ ì •ë³´]\n{team_info_text}\n"
        f"[ìë™ ê³„ì‚°]\n{auto_calc_text}\n"
    )

    answer = ""
    if _OPENAI_CLIENT and ctx.strip():
        msgs = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n\n[ì§ˆë¬¸]\n{question}"},
        ]
        try:
            resp = _OPENAI_CLIENT.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=msgs,
                temperature=0.1,
            )
            answer = resp.choices[0].message.content
        except Exception as e:
            answer = f"âŒ LLM ì˜¤ë¥˜: {e}"
    else:
        answer = f"(OPENAI_API_KEY ì—†ìŒ ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±)\n\n{ctx[:800]}"

    if show_sources and metas:
        srcs = [f"ğŸ“„ `{os.path.basename(m.get('path',''))}`" for m in metas if m.get("path")]
        if srcs:
            answer += "\n\n---\n**ğŸ“‚ ì°¸ê³  ë¬¸ì„œ:**\n" + "\n".join(srcs)
    return answer


# ---------------- Streamlit UI ----------------
tab1, tab2 = st.tabs(["ğŸ’¬ ì¼ë°˜ ì‚¬ìš©ì", "ğŸ›  ê´€ë¦¬ì"])

# ----------- ì¼ë°˜ ì‚¬ìš©ì íƒ­ -----------
with tab1:
    if "history" not in st.session_state:
        st.session_state.history = []
    user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
    if user_input:
        answer = safe_rag_query(user_input)
        st.session_state.history.append((user_input, answer))
        st.markdown("### ğŸ¤– ë‹µë³€")
        st.write(answer)
        st.write("---")

    if st.session_state.history:
        st.markdown("### ğŸ“œ ì´ì „ ëŒ€í™” ê¸°ë¡")
        for idx, (q, a) in enumerate(st.session_state.history, 1):
            with st.expander(f"Q{idx}: {q}", expanded=False):
                st.markdown(f"**A:** {a}")

# ----------- ê´€ë¦¬ì íƒ­ -----------
with tab2:
    with st.expander("ğŸ“‚ ì •ì • ìë£Œ ì¶”ê°€ (correction/)", expanded=False):
        st.info("ì •ì •ìë£Œ í´ë”ì— txt ë˜ëŠ” csv íŒŒì¼ì„ ì¶”ê°€í•˜ë©´ RAG ìƒ‰ì¸ ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
    with st.expander("ğŸ”’ íˆë“  ë£° ì¶”ê°€ (hidden/)", expanded=False):
        st.info("RAGì€ / ragëŠ” ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¬¸ì¥ì€ ë‹µë³€ì— ì˜í–¥ì„ ì£¼ì§€ë§Œ ì§ì ‘ ë…¸ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    if st.button("ğŸ§± ìƒ‰ì¸ ì¬ë¹Œë“œ"):
        safe_build_index()
        st.success("ìƒ‰ì¸ ì¬ë¹Œë“œ ì™„ë£Œ âœ…")

    st.divider()
    st.subheader("ğŸ” ê´€ë¦¬ììš© í…ŒìŠ¤íŠ¸ ì§ˆì˜")
    admin_question = st.text_input("í…ŒìŠ¤íŠ¸í•  ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (Enterë¡œ ì‹¤í–‰):", key="admin_question")
    if admin_question.strip():
        show_src = st.checkbox("ì°¸ê³  ë¬¸ì„œ ê²½ë¡œ í‘œì‹œ", value=True, key="show_sources_admin")
        answer = safe_rag_query(admin_question, show_sources=show_src)
        st.markdown("### ğŸ§  RAG ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°")
        st.write(answer)
    st.caption(f"ğŸ•’ ì„œë²„ ê¸°ì¤€ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    st.divider()
    st.subheader("ğŸ§­ ì¡°ì§ë„ ë¯¸ë¦¬ë³´ê¸°")

    org_path = os.path.join(FAQDIR, "org_info.csv")
    if os.path.exists(org_path):
        try:
            df = pd.read_csv(org_path)
            search_term = st.text_input("ğŸ” íŒ€ëª… ë˜ëŠ” íŒ€ì¥ìœ¼ë¡œ ê²€ìƒ‰:", key="org_search").strip()
            if search_term:
                filtered_df = df[
                    df["íŒ€ëª…"].astype(str).str.contains(search_term, case=False)
                    | df["íŒ€ì¥"].astype(str).str.contains(search_term, case=False)
                ]
            else:
                filtered_df = df
            st.dataframe(filtered_df[["íŒ€ëª…", "íŒ€ì¥", "íŒ€ì›ìˆ˜", "íŒ€ì›"]], use_container_width=True, height=500)
            if not filtered_df.empty:
                team_choice = st.selectbox("íŒ€ ì„¸ë¶€ì •ë³´ ë³´ê¸°:", filtered_df["íŒ€ëª…"])
                team_row = filtered_df[filtered_df["íŒ€ëª…"] == team_choice].iloc[0]
                with st.expander(f"ğŸ“‚ {team_row['íŒ€ëª…']} ìƒì„¸ êµ¬ì„±ì› ë³´ê¸°", expanded=False):
                    st.write(f"**íŒ€ì¥:** {team_row['íŒ€ì¥']}")
                    st.write(f"**íŒ€ì›ìˆ˜:** {team_row['íŒ€ì›ìˆ˜']}")
                    st.write("**íŒ€ì›:**")
                    st.markdown("- " + "\n- ".join([m.strip() for m in str(team_row['íŒ€ì›']).split(",") if m.strip()]))
        except Exception as e:
            st.error(f"âŒ ì¡°ì§ë„ CSV íŒŒì‹± ì˜¤ë¥˜: {e}")
    else:
        st.warning("âš ï¸ ì¡°ì§ë„ íŒŒì¼(org_info.csv)ì´ data/vectorstore í´ë”ì— ì—†ìŠµë‹ˆë‹¤.")
