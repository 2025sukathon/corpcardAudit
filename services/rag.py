# services/rag.py
from __future__ import annotations
import os, glob, csv, re, sys
from typing import Optional, List, Tuple, Dict
from datetime import datetime, timedelta

import pandas as pd
from openpyxl import load_workbook
import httpx
from chromadb import PersistentClient
from chromadb.utils import embedding_functions
from dotenv import load_dotenv

load_dotenv()

print("ğŸ§  Python ì‹¤í–‰ ê²½ë¡œ:", sys.executable)
print("ğŸ“¦ httpx ë²„ì „:", httpx.__version__)

# ---------------- OpenAI í´ë¼ì´ì–¸íŠ¸ ----------------
try:
    from openai import OpenAI as _OpenAI
except Exception:
    _OpenAI = None

def _make_openai_client() -> Optional["_OpenAI"]:
    if not _OpenAI:
        return None
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ OPENAI_API_KEYê°€ .envì—ì„œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    os.environ["OPENAI_API_KEY"] = api_key

    http_proxy  = os.getenv("HTTP_PROXY")  or os.getenv("http_proxy")
    https_proxy = os.getenv("HTTPS_PROXY") or os.getenv("https_proxy")

    client_args = {"timeout": 30.0}
    if http_proxy or https_proxy:
        proxies = {}
        if http_proxy:
            proxies["http://"] = http_proxy
        if https_proxy:
            proxies["https://"] = https_proxy
        client_args["proxies"] = proxies

    http_client = httpx.Client(**client_args) if client_args else None
    return _OpenAI(http_client=http_client)

_OPENAI_CLIENT = _make_openai_client()
_OPENAI_EMB_MODEL = os.getenv("EMB_MODEL", "text-embedding-3-small")

# ---------------- ê²½ë¡œ ì„¤ì • ----------------
DBDIR  = "data/vectorstore/chroma"
FAQDIR = "data/vectorstore"

# ---------------- Chroma Client ----------------
def _chroma_client():
    os.makedirs(DBDIR, exist_ok=True)
    return PersistentClient(path=DBDIR)

# ---------------- OpenAI ì„ë² ë”© ----------------
class OpenAIEmbedder:
    """ChromaDB 0.4.16+ í˜¸í™˜ ì„ë² ë” (ê¸´ ì…ë ¥ ìë™ ë¶„í• )"""
    def __init__(self, client, model_name: str):
        self.client = client
        self.model_name = model_name
        self._name = f"openai:{model_name}"

    def name(self):
        """Chromaê°€ í˜¸ì¶œí•  ë•Œ ì‚¬ìš©í•˜ëŠ” ì‹ë³„ì"""
        return self._name

    def __call__(self, input: list[str]) -> list[list[float]]:
        """
        ê¸´ ì…ë ¥ ìë™ ë¶„í•  (8192 tokens ì´ˆê³¼ ë°©ì§€)
        - í•œê¸€ ê¸°ì¤€ 6000ì ë‹¨ìœ„ë¡œ chunk
        - ì‹¤íŒ¨í•œ chunkëŠ” dummy ë²¡í„°ë¡œ ì±„ì›Œ 1:1 ë§¤í•‘ ìœ ì§€
        """
        def chunk_text(text: str, max_chars: int = 6000) -> list[str]:
            return [text[i:i + max_chars] for i in range(0, len(text), max_chars)]

        safe_inputs = []
        for t in input:
            if isinstance(t, str) and len(t) > 6000:
                safe_inputs.extend(chunk_text(t))
            else:
                safe_inputs.append(t)

        all_embeddings = []
        for chunk in safe_inputs:
            try:
                resp = self.client.embeddings.create(model=self.model_name, input=chunk)
                all_embeddings.extend([d.embedding for d in resp.data])
            except Exception as e:
                print(f"âŒ Embedding error for chunk ({len(str(chunk))} chars): {e}")
                dim = 1536 if "3-small" in self.model_name else 3072
                all_embeddings.append([0.0] * dim)

        # ê°œìˆ˜ ë³´ì •
        if len(all_embeddings) < len(safe_inputs):
            diff = len(safe_inputs) - len(all_embeddings)
            dim = 1536 if "3-small" in self.model_name else 3072
            for _ in range(diff):
                all_embeddings.append([0.0] * dim)
        elif len(all_embeddings) > len(safe_inputs):
            all_embeddings = all_embeddings[:len(safe_inputs)]

        return all_embeddings

    # âœ… Chromaê°€ query ì‹œ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œ
    def embed_query(self, input: list[str]) -> list[list[float]]:
        return self.__call__(input)

    # âœ… Chromaê°€ upsert ì‹œ í˜¸ì¶œí•˜ëŠ” ë©”ì„œë“œ
    def embed_documents(self, input: list[str]) -> list[list[float]]:
        return self.__call__(input)


def _embedding_function():
    if _OPENAI_CLIENT:
        return OpenAIEmbedder(_OPENAI_CLIENT, _OPENAI_EMB_MODEL)
    return embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

# ---------------- íŒŒì¼ ë¦¬ë” ----------------
def _read(path: str) -> str:
    p = path.lower()
    if p.endswith((".md", ".txt")):
        return open(path, "r", encoding="utf-8").read()
    if p.endswith(".pdf"):
        try:
            from pypdf import PdfReader
            return "\n".join(page.extract_text() or "" for page in PdfReader(path).pages)
        except Exception:
            return ""
    return ""

# ---------------- QA í¬ë§· ----------------
def _read_qa_csv(path: str) -> list[tuple[str, str]]:
    rows = []
    with open(path, encoding="utf-8") as f:
        for r in csv.DictReader(f):
            q, a = (r.get("question") or "").strip(), (r.get("answer") or "").strip()
            if q and a:
                rows.append((q, a))
    return rows

def _read_qa_md(path: str) -> list[tuple[str, str]]:
    txt = open(path, "r", encoding="utf-8").read()
    pairs = []
    for block in txt.split("### Q:")[1:]:
        q, _, rest = block.partition("\n")
        a_tag = "A:"
        a = rest.split("\n", 1)[0] if a_tag not in rest else rest.split(a_tag, 1)[1].strip()
        q, a = q.strip(), a.strip()
        if q and a:
            pairs.append((q, a))
    return pairs

# ---------------- ìˆ¨ê¹€ / ì •ì • ----------------
def _read_hidden_data():
    hidden_dir = os.path.join(FAQDIR, "hidden")
    correction_dir = os.path.join(FAQDIR, "correction")
    hidden_txt, correction_txt = [], []
    for folder, acc in [(hidden_dir, hidden_txt), (correction_dir, correction_txt)]:
        if not os.path.exists(folder):
            continue
        for f in glob.glob(os.path.join(folder, "*.txt")) + glob.glob(os.path.join(folder, "*.csv")):
            try:
                acc.append(open(f, encoding="utf-8").read())
            except Exception as e:
                print(f"âš  {folder} íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    return "\n".join(hidden_txt), "\n".join(correction_txt)

# ---------------- ì¡°ì§ë„ ----------------
def _read_org_info() -> Optional[pd.DataFrame]:
    org_path = os.path.join(FAQDIR, "org_info.csv")
    if not os.path.exists(org_path):
        print("âš ï¸ ì¡°ì§ë„ íŒŒì¼(org_info.csv)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    try:
        return pd.read_csv(org_path, encoding="utf-8")
    except Exception as e:
        print(f"âŒ ì¡°ì§ë„ CSV íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def _count_members_from_org(org_path: str, leader_name: str) -> tuple[int | None, str | None]:
    try:
        df = pd.read_csv(org_path)
        row = df[df["íŒ€ì¥"] == leader_name]
        if row.empty:
            return None, None
        if "íŒ€ì›ìˆ˜" in df.columns:
            team_count = int(row.iloc[0]["íŒ€ì›ìˆ˜"])
        else:
            members_str = str(row.iloc[0].get("íŒ€ì›", "")).strip()
            team_count = len([m for m in members_str.split(",") if m.strip()])
        return team_count, row.iloc[0].get("íŒ€ëª…", None)
    except Exception as e:
        print(f"âŒ ì¡°ì§ë„ CSV íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None, None

# ---------------- ìƒ‰ì¸ ë¹Œë“œ ----------------
def build_index_all(verbose=True):
    cli = _chroma_client()
    try:
        cli.delete_collection("faqs_openai")
        if verbose: print("âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
    except Exception:
        if verbose: print("â„¹ï¸ ê¸°ì¡´ ì»¬ë ‰ì…˜ ì—†ìŒ")

    col = cli.get_or_create_collection("faqs_openai", embedding_function=_embedding_function())
    ids, docs, metas = [], [], []
    exts = [".md", ".txt", ".pdf", ".csv", ".xlsx"]
    files = sum([glob.glob(os.path.join(FAQDIR, f"*{ext}")) for ext in exts], [])
    MAX_CHARS = 6000

    for f in files:
        text = ""
        try:
            if f.endswith((".md", ".txt")):
                text = open(f, "r", encoding="utf-8").read()
            elif f.endswith(".pdf"):
                from pypdf import PdfReader
                text = "\n".join([p.extract_text() or "" for p in PdfReader(f).pages])
            elif f.endswith(".csv"):
                df = pd.read_csv(f, encoding="utf-8")
                text = "\n".join([", ".join([f"{c}: {v}" for c, v in row.items()]) for _, row in df.iterrows()])
            elif f.endswith(".xlsx"):
                wb = load_workbook(f, data_only=True)
                for s in wb.sheetnames:
                    ws = wb[s]
                    for row in ws.iter_rows(values_only=True):
                        text += ", ".join([str(v) for v in row if v]) + "\n"
        except Exception as e:
            print(f"âš ï¸ {os.path.basename(f)} ì½ê¸° ì˜¤ë¥˜: {e}")
            continue

        if text.strip():
            for i in range(0, len(text), MAX_CHARS):
                chunk = text[i:i+MAX_CHARS]
                ids.append(f"{os.path.basename(f)}_part{i//MAX_CHARS+1}")
                docs.append(chunk)
                metas.append({"path": f, "part": i//MAX_CHARS+1})

    if ids:
        col.upsert(ids=ids, documents=docs, metadatas=metas)
        if verbose: print(f"âœ… {len(ids)}ê°œ ë¬¸ì„œ ìƒ‰ì¸ ì™„ë£Œ")

    qa_files = glob.glob(f"{FAQDIR}/*.csv") + glob.glob(f"{FAQDIR}/faq_qa.md") + glob.glob(f"{FAQDIR}/*_qa.md")
    q_ids, q_docs, q_metas = [], [], []
    for f in qa_files:
        pairs = _read_qa_csv(f) if f.endswith(".csv") else _read_qa_md(f)
        for i, (q, a) in enumerate(pairs):
            q_ids.append(f"{os.path.basename(f)}::Q{i+1}")
            q_docs.append(f"[Q] {q}\n[A] {a}")
            q_metas.append({"path": f, "type": "qa"})
    if q_ids:
        col.upsert(ids=q_ids, documents=q_docs, metadatas=q_metas)
        if verbose: print(f"âœ… {len(q_ids)}ê°œ Q&A ìƒ‰ì¸ ì™„ë£Œ")

    org_df = _read_org_info()
    if org_df is not None:
        org_text = "\n".join([
            f"{r['íŒ€ëª…']}íŒ€ ({r['íŒ€ì¥']}): {r['íŒ€ì›ìˆ˜']}ëª…, {r['íŒ€ì›']}"
            for _, r in org_df.iterrows()
        ])
        col.upsert(ids=["org_info"], documents=[org_text], metadatas=[{"path": "org_info.csv", "type": "org"}])
        if verbose: print("âœ… ì¡°ì§ë„ ìƒ‰ì¸ ì™„ë£Œ")


# ---------------- RAG ì§ˆì˜ ----------------
def safe_rag_query(question: str, k=3, show_sources=False):
    cli = _chroma_client()
    col = cli.get_or_create_collection("faqs_openai", embedding_function=_embedding_function())
    r = col.query(query_texts=[question], n_results=k)

    ctx = "\n\n".join(r["documents"][0]) if r.get("documents") else ""
    metas = r["metadatas"][0] if r.get("metadatas") else []

    now = datetime.now()
    today_str = now.strftime("%Y-%m-%d (%A)")
    week_start = (now - timedelta(days=now.weekday())).strftime("%Y-%m-%d")
    week_end = (now + timedelta(days=6 - now.weekday())).strftime("%Y-%m-%d")
    month_str = now.strftime("%Y-%m")

    hidden_context, correction_rules = _read_hidden_data()

    designated_amounts = {}
    for line in hidden_context.splitlines():
        m = re.match(r"(\S+)\s*(\d+(?:,\d+)*)ì›", line)
        if m:
            rank, amt = m.groups()
            designated_amounts[rank] = int(amt.replace(",", ""))

    match_name_rank = re.search(r"([ê°€-í£A-Za-z]+)\s*(íŒ€ì¥|ë¶€ì¥|ì„ì›|ì°¨ì¥|ê³¼ì¥|ëŒ€ë¦¬|ì‚¬ì›)", question)
    user_name, user_rank = (match_name_rank.groups() if match_name_rank else (None, None))

    org_path = os.path.join(FAQDIR, "org_info.csv")
    member_count, team_name = _count_members_from_org(org_path, user_name) if user_name else (None, None)

    team_info_text, auto_calc_text = "", ""
    if member_count and team_name:
        team_info_text = f"{team_name} ({user_rank} {user_name})ì˜ íŒ€ì› ìˆ˜ëŠ” {member_count}ëª…ì…ë‹ˆë‹¤."
    if "ì—…ë¬´ì¶”ì§„ë¹„" in question and user_rank in designated_amounts:
        base = designated_amounts[user_rank]
        if member_count:
            total = base * member_count
            auto_calc_text = f"ğŸ’° ìë™ ê³„ì‚°: {user_rank} {user_name} - íŒ€ì› {member_count}ëª… Ã— {base:,}ì› = {total:,}ì›"
        else:
            auto_calc_text = f"ğŸ’° ìë™ ê³„ì‚°: {user_rank} ê¸°ì¤€ 1ì¸ë‹¹ {base:,}ì›"

    system_prompt = (
        f"ì˜¤ëŠ˜ì€ {today_str}ì´ë©°, ì´ë²ˆ ì£¼ëŠ” {week_start}~{week_end}, ì´ë²ˆ ë‹¬ì€ {month_str}ì›”ì…ë‹ˆë‹¤.\n"
        "ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ê°„ê²°í•˜ê³  ì •í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
        "hidden í´ë”ì˜ ë‚´ìš©ì€ ë‚´ë¶€ ê·œì¹™ ì°¸ê³ ìš©ì´ë©°, ë‹µë³€ì— ì§ì ‘ ë…¸ì¶œí•˜ì§€ ë§ˆì„¸ìš”.\n\n"
        f"[ìˆ¨ê¹€ ê·œì¹™]\n{hidden_context}\n"
        f"[ì •ì • ìë£Œ]\n{correction_rules}\n"
        f"[ì¡°ì§ë„ ì •ë³´]\n{team_info_text}\n"
        f"[ìë™ ê³„ì‚°]\n{auto_calc_text}\n"
    )

    if _OPENAI_CLIENT and ctx.strip():
        try:
            resp = _OPENAI_CLIENT.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"[ì»¨í…ìŠ¤íŠ¸]\n{ctx}\n\n[ì§ˆë¬¸]\n{question}"},
                ],
                temperature=0.1,
            )
            answer = resp.choices[0].message.content
        except Exception as e:
            answer = f"âŒ LLM ì˜¤ë¥˜: {e}"
    else:
        answer = f"(OPENAI_API_KEY ì—†ìŒ ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±)\n\n{ctx[:800]}"

    if show_sources and metas:
        srcs = [f"ğŸ“„ `{os.path.basename(m.get('path',''))}`" for m in metas if m.get("path")]
        if srcs:
            answer += "\n\n---\n**ğŸ“‚ ì°¸ê³  ë¬¸ì„œ:**\n" + "\n".join(srcs)
    return answer

# rag.py íŒŒì¼ ëì— ì¶”ê°€

# ---------------- ë²•ì¸ì¹´ë“œ ë§¤ì¹­ ê¸°ëŠ¥ (ìˆ˜ì •) ----------------
import re

def match_corporate_card(approval_df: pd.DataFrame, expense_df: pd.DataFrame, limits_df: pd.DataFrame) -> tuple:
    """ë²•ì¸ì¹´ë“œ ìŠ¹ì¸ë‚´ì—­ê³¼ ì§€ì¶œê²°ì˜ ë§¤ì¹­"""
    
    # í•œë„ê¸ˆì•¡, ìŠ¹ì¸ë²ˆí˜¸ ì—´ ì¶”ê°€
    expense_df.insert(0, 'í•œë„ê¸ˆì•¡', '')
    expense_df['ìŠ¹ì¸ë²ˆí˜¸'] = ''
    
    # ìŠ¹ì¸ë‚´ì—­ì—ì„œ ë§¤ì¹­ëœ í–‰ ì¸ë±ìŠ¤ ì €ì¥
    matched_approval_indices = []
    
    # ê° ì§€ì¶œê²°ì˜ í–‰ ì²˜ë¦¬
    for idx, exp_row in expense_df.iterrows():
        basic_summary = str(exp_row.get('ê¸°ë³¸ì ìš”', ''))
        
        # ê¸°ë³¸ì ìš”ì—ì„œ ì²« 4ìë¦¬ ìˆ«ì ì¶”ì¶œ (ì§€ì¶œê²°ì˜)
        four_digit_match = re.match(r'^(\d{4})', basic_summary)
        if four_digit_match:
            four_digit_key = four_digit_match.group(1)
            
            # limits.csvì—ì„œ ë§¤ì¹­í•˜ì—¬ í•œë„ê¸ˆì•¡ ì„¤ì •
            for _, limit_row in limits_df.iterrows():
                if str(limit_row['ì ìš”']) == four_digit_key:
                    amount = int(limit_row['ê¸ˆì•¡'])
                    # -1, -2 ê°™ì€ íŠ¹ìˆ˜ê°’ ì²˜ë¦¬
                    if amount > 0:
                        expense_df.at[idx, 'í•œë„ê¸ˆì•¡'] = f"{amount:,}"
                    elif amount == -1:
                        expense_df.at[idx, 'í•œë„ê¸ˆì•¡'] = "í•œë„ì—†ìŒ"
                    elif amount == -2:
                        expense_df.at[idx, 'í•œë„ê¸ˆì•¡'] = "ì‹¤ë¹„ì •ì‚°"
                    else:
                        expense_df.at[idx, 'í•œë„ê¸ˆì•¡'] = str(amount)
                    break
        
        # 'ë²•ì¹´'ê°€ ì—†ê³  'ê°œì¸' í¬í•¨ì‹œ ìŠ¹ì¸ë²ˆí˜¸ ë§¤ì¹­ ìŠ¤í‚µ
        if 'ë²•ì¹´' not in basic_summary and 'ê°œì¸' in basic_summary:
            continue
        
        # ë²•ì¸ì¹´ë“œì¸ ê²½ìš° ìŠ¹ì¸ë‚´ì—­ê³¼ ë§¤ì¹­
        if 'ë²•ì¹´' in basic_summary:
            exp_time = str(exp_row.get('ìŠ¹ì¸ì‹œê°„', ''))
            
            # ìŠ¹ì¸ë‚´ì—­ì—ì„œ ë™ì¼ ì‹œê°„ ì°¾ê¸°
            for app_idx, app_row in approval_df.iterrows():
                if str(app_row.get('ìŠ¹ì¸ì‹œê°„', '')) == exp_time and exp_time != '':
                    # ë‚ ì§œ í˜•ì‹ ë³€í™˜ ë° ë¹„êµ
                    exp_date = str(exp_row.get('ì¦ë¹™ì¼ì', ''))
                    # "2025-09-04(ëª©)" í˜•ì‹ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œ
                    if '(' in exp_date:
                        exp_date = exp_date.split('(')[0]
                    exp_date = exp_date.replace('-', '.')
                    
                    app_date = str(app_row.get('ìŠ¹ì¸ì¼', ''))
                    if exp_date == app_date:
                        # ìŠ¹ì¸ë²ˆí˜¸ ë§¤ì¹­
                        expense_df.at[idx, 'ìŠ¹ì¸ë²ˆí˜¸'] = str(app_row.get('ìŠ¹ì¸ë²ˆí˜¸', ''))
                        matched_approval_indices.append(app_idx)
                        break
    
    return expense_df, matched_approval_indices

def extract_four_digit_code(text: str) -> str:
    """ê¸°ë³¸ì ìš”ì—ì„œ ì²˜ìŒ ë„¤ ìë¦¬ ìˆ«ì ì¶”ì¶œ"""
    match = re.match(r'(\d{4})', str(text))
    return match.group(1) if match else ""

# ---------------- ì—”í„°í‚¤ ì…ë ¥ í—¬í¼ ----------------
def format_question_with_enter(question: str) -> str:
    """ì—”í„°í‚¤ ì…ë ¥ ì§€ì›ì„ ìœ„í•œ ì§ˆë¬¸ í¬ë§·íŒ…"""
    return question.strip().replace('\n', ' ')